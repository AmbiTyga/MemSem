{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MemSemV2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "302b5a64a71d44078f76d3418d918f12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_48b78c97d1d64d41b19542473f45518e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_69c961ad597f4ee7ab89dbdc33fcdcf5",
              "IPY_MODEL_e85f40227655471086b1ab9cecb695a4"
            ]
          }
        },
        "48b78c97d1d64d41b19542473f45518e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69c961ad597f4ee7ab89dbdc33fcdcf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b3ddb98c97264189a304129dbf9ba790",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_802bd6b8011d4c9199702ff393d90c4c"
          }
        },
        "e85f40227655471086b1ab9cecb695a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8962f73065a4407bec2912244bab59c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.55MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25e8449f56db4338b5c4787ba7505012"
          }
        },
        "b3ddb98c97264189a304129dbf9ba790": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "802bd6b8011d4c9199702ff393d90c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8962f73065a4407bec2912244bab59c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25e8449f56db4338b5c4787ba7505012": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "spyjdgFBmHis",
        "colab_type": "code",
        "outputId": "714c9d45-3f97-4b79-9b01-9f7aa0eee666",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_dir = \"/content/gdrive/My Drive/\"\n",
        "base_dir = root_dir + 'memotion_analysis/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1K5wv8hm3rlR",
        "colab_type": "text"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjXgYUN4BwUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLu3vAkUDHhJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_rMD0SSd6H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing import image as keras_image\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKSHwrMuczpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, concatenate\n",
        "from transformers import TFBertModel\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9WUH7hkB0-u",
        "colab_type": "text"
      },
      "source": [
        "### DATA Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjPSodLmeAM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_csv(\"/content/train_final_V2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awR9_-Qierjn",
        "colab_type": "code",
        "outputId": "e4b590f4-2653-43ab-90b7-183c6cff46c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "dataframe.dropna(axis = 0,inplace = True)\n",
        "dataframe.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 7614 entries, 0 to 7622\n",
            "Data columns (total 3 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   text               7614 non-null   object\n",
            " 1   filepath           7614 non-null   object\n",
            " 2   Overall_Sentiment  7614 non-null   int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 237.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJHsNhIPeuMA",
        "colab_type": "code",
        "outputId": "1baeacf7-2229-4af8-f0f7-40cd9c126f1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Split train and validation dataframes\n",
        "train_test_factor = 0.85\n",
        "mask = np.random.rand(len(dataframe)) < train_test_factor\n",
        "validation_dataframe = dataframe[~mask]\n",
        "train_dataframe = dataframe[mask]\n",
        "\n",
        "# Shuffle train dataframe\n",
        "train_dataframe = train_dataframe.reset_index(drop=True)\n",
        "print(train_dataframe['Overall_Sentiment'].value_counts())\n",
        "validation_dataframe = validation_dataframe.reset_index(drop=True)\n",
        "print(validation_dataframe['Overall_Sentiment'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2    2878\n",
            "0    1914\n",
            "1    1639\n",
            "Name: Overall_Sentiment, dtype: int64\n",
            "2    525\n",
            "0    351\n",
            "1    307\n",
            "Name: Overall_Sentiment, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laEcU-ztlxx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = {'image':[],'text':[],'label':[]}\n",
        "validation = {'image':[],'text':[],'label':[]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcXoWECumYyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image):\n",
        "  img = image.copy()\n",
        "  img = keras_image.img_to_array(img)\n",
        "  img = img//255.0\n",
        "  return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUCKO20mmcdA",
        "colab_type": "code",
        "outputId": "58f896bd-b074-48e1-fe44-0697438d0fba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "# train\n",
        "for index,filepath in enumerate(train_dataframe['filepath']):\n",
        "  try:\n",
        "    image = keras_image.load_img(filepath, target_size=(224, 224),interpolation='bicubic')\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "  image = preprocess_image(image)\n",
        "  train['image'].append(image)\n",
        "  train['text'].append(train_dataframe.text[index])\n",
        "  train['label'].append(train_dataframe.Overall_Sentiment[index])\n",
        "\n",
        "# validation\n",
        "for index,filepath in enumerate(validation_dataframe['filepath']):\n",
        "  try:\n",
        "    image = keras_image.load_img(filepath, target_size=(224, 224),interpolation='bicubic')\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    continue\n",
        "\n",
        "  image = preprocess_image(image)\n",
        "  validation['image'].append(image)\n",
        "  validation['text'].append(validation_dataframe.text[index])\n",
        "  validation['label'].append(validation_dataframe.Overall_Sentiment[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/dr_evil_football-meme-009-dr-evil-super-bowl.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/harvey_Steve-Harvey-Miss-Universe-Screw-Up-Memes12.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/hitler_funny-memes-on-Hitler-2.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/harvey_14.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/sexist_meme4_640x700.jpg'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/Image.py:932: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  \"Palette images with Transparency expressed in bytes should be \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/seal_seal-cute-W630.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/negative/hitler_Funny-memes-of-hitler.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/minion_Minion-Memes191.jpg'\n",
            "image file is truncated (52 bytes not processed)\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/harry_harry-potter-memes-600-pokemon.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/barney_Barneys-Dating-Advice-e1333644417653.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/spiderman_60s-spiderman-meme-collection-1mut.com-8.png'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/skeptical_skeptical-baby-meme-11.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/best_2017_meme-costumes-2017-admirable-2017-pun-halloween-costume-ideas-saltypun-of-meme-costumes-2017.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/negative/third_Skeptical-Third-World-Kid-meme-collection-1mut.com-16.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/trump_85145592.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/gene_85YOUR-ARGUMENT-IS-INVALID-meme-collection-1mut.com-1.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/hitler_Best-Funny-Hitler-Memes.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/bean_whats-is-the-face-expression-of-mr-bean-hahahah-mr-bean-meme-on-me.png'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/seal_snowball-of-cuteness-W630.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/best_2017_meme-costumes-2017-great-funny-halloween-costumes-2017-memes-of-meme-costumes-2017.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/minion_Minion-gift-to-baby-ghost-halloween-meme-635x529.jpg'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "image file is truncated (1 bytes not processed)\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/positive/harry_serveous-snape-memes.jpg'\n",
            "cannot identify image file '/content/gdrive/My Drive/memotion_analysis/dataset/train/neutral/avengers_Avengers-Endgame-Meme-003-first-watched-cursed-with-knowledge.jpg'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X23a0PibUG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(\"/content/gdrive/My Drive/memotion_analysis/train.npy\",train['image'])\n",
        "np.save(\"/content/gdrive/My Drive/memotion_analysis/val.npy\",validation['image'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYAg8JHBnUSQ",
        "colab_type": "code",
        "outputId": "da471e0e-1c81-437d-c722-81c3c89a8b45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(len(train['image']),len(train['text']),len(train['label']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6409, 6409, 6409)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdxy5Sv3utFX",
        "colab_type": "code",
        "outputId": "ba1ab087-bc9b-499c-b99d-aa6177e33715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(len(validation['image']),len(validation['text']),len(validation['label']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1180, 1180, 1180)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtpgzjlm-gVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.DataFrame(train)\n",
        "val = pd.DataFrame(validation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAxw67fr6_iP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv(\"/content/gdrive/My Drive/memotion_analysis/train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8DUIRjo_1z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val.to_csv(\"/content/gdrive/My Drive/memotion_analysis/val.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqjUw_WaB7Tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceQk6BA8B8DE",
        "colab_type": "text"
      },
      "source": [
        "## Main Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB0jVIAqAMfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"/content/gdrive/My Drive/memotion_analysis/train.csv\")\n",
        "val = pd.read_csv(\"/content/gdrive/My Drive/memotion_analysis/val.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyxQtGub7Ysd",
        "colab_type": "text"
      },
      "source": [
        "## Image data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI7mfU3QDxEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = np.load('/content/gdrive/My Drive/memotion_analysis/train.npy')\n",
        "test_images = np.load('/content/gdrive/My Drive/memotion_analysis/val.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPeDR3qI7a7m",
        "colab_type": "text"
      },
      "source": [
        "## Text data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSlzrx44IPMX",
        "colab_type": "code",
        "outputId": "4a877989-1549-429c-98da-64701ecfa280",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "302b5a64a71d44078f76d3418d918f12",
            "48b78c97d1d64d41b19542473f45518e",
            "69c961ad597f4ee7ab89dbdc33fcdcf5",
            "e85f40227655471086b1ab9cecb695a4",
            "b3ddb98c97264189a304129dbf9ba790",
            "802bd6b8011d4c9199702ff393d90c4c",
            "f8962f73065a4407bec2912244bab59c",
            "25e8449f56db4338b5c4787ba7505012"
          ]
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "302b5a64a71d44078f76d3418d918f12",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHzyd2sLPUTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_id_mask_train = [tokenizer.encode_plus(x, max_length=52, pad_to_max_length=True,) for x in train['text']]\n",
        "input_id_mask_val = [tokenizer.encode_plus(x, max_length=52, pad_to_max_length=True) for x in val['text']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMUxf2g_SEN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_text = pd.DataFrame(input_id_mask_train)\n",
        "val_text = pd.DataFrame(input_id_mask_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7VI1izU7okJ",
        "colab_type": "code",
        "outputId": "bec4f7c7-1cf5-44f3-cf1a-4d3076fa2484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_text.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['input_ids', 'token_type_ids', 'attention_mask'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrRZsg5v3zQS",
        "colab_type": "text"
      },
      "source": [
        "## Processed input for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSNIlVpuKIF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_input_ids = tf.stack(train_text.input_ids.apply(tf.convert_to_tensor).values)\n",
        "train_input_masks = tf.stack(train_text.attention_mask.apply(tf.convert_to_tensor).values)\n",
        "train_segment_ids = tf.stack(train_text.token_type_ids.apply(tf.convert_to_tensor).values)\n",
        "\n",
        "test_input_ids = tf.stack(val_text.input_ids.apply(tf.convert_to_tensor).values)\n",
        "test_input_masks = tf.stack(val_text.attention_mask.apply(tf.convert_to_tensor).values)\n",
        "test_segment_ids = tf.stack(val_text.token_type_ids.apply(tf.convert_to_tensor).values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TPo64Wvwpsj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_imagesX = tf.convert_to_tensor(train_images)\n",
        "trainY = tf.stack(train.label.values)\n",
        "\n",
        "test_imagesX = tf.convert_to_tensor(test_images)\n",
        "testY = tf.stack(val.label.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnIiRx205n4Z",
        "colab_type": "code",
        "outputId": "89d02384-b879-494a-ce37-f4c679cdbd86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_input_ids.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([50, 52])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPvsXfIx5tbx",
        "colab_type": "code",
        "outputId": "ec8227ac-0fe1-4a7e-8204-2df20a770b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_input_ids.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([10, 52])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKoxMQek5xD0",
        "colab_type": "code",
        "outputId": "fe5d044a-fb31-46b1-cc0f-472d1f92b3ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_imagesX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([50, 224, 224, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqjcbNSn53Y5",
        "colab_type": "code",
        "outputId": "9d81cdc4-c51c-47f3-ee68-51fe327aabaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJZRQaJ34LN",
        "colab_type": "text"
      },
      "source": [
        "## Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5qP3U_QSO2B",
        "colab_type": "code",
        "outputId": "98ae2cfc-fb9c-4a94-809f-a3ccf100928b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max([len(s.split()) for s in train['text']])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqREZ6PAZFdz",
        "colab_type": "code",
        "outputId": "2a8894d1-dd61-479e-c8d7-46f138cdcb8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "l=[len(s.split()) for s in train['text']]\n",
        "count=0.0\n",
        "for i in l:\n",
        "    if i>52:\n",
        "        count+=1\n",
        "print(count,len(l))\n",
        "print(count/len(l))\n",
        "MAX_SEQUENCE_LENGTH = 52 ## State after running this cell"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.0 6409\n",
            "0.002028397565922921\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlXg7U6K37sR",
        "colab_type": "text"
      },
      "source": [
        "## Multi-Modal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjX9mQFpdw9r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
        "vis_model = VGG19(include_top=False)\n",
        "\n",
        "token_inputs = Input((MAX_SEQUENCE_LENGTH), dtype=tf.int32, name='input_word_ids')\n",
        "mask_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
        "seg_inputs = Input((MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_segments')\n",
        "bert_output = bert_model([token_inputs, mask_inputs, seg_inputs])[1]\n",
        "bert_output = Dense(768,activation='relu')(bert_output)\n",
        "bert_output = Dropout(0.4)(bert_output)\n",
        "text_repr = Dense(32, activation='relu')(bert_output)\n",
        "\n",
        "vis_input = Input(shape=(224,224,3))\n",
        "vis_feature = vis_model(vis_input)\n",
        "flat = Flatten()(vis_feature)\n",
        "flat = Dense(2742, activation='relu')(flat)\n",
        "flat = Dropout(0.4)(flat)\n",
        "visual_repr = Dense(32,activation='relu')(flat)\n",
        "\n",
        "combine_repr = concatenate([text_repr, visual_repr])\n",
        "com_drop= Dropout(0.4)(combine_repr)\n",
        "prediction = Dense(1,activation='sigmoid')(com_drop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i50BwZu4f_ku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "memsem = Model(inputs = [token_inputs, mask_inputs, seg_inputs,vis_input], outputs = prediction)\n",
        "memsem.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWY8iBt4sEPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(\n",
        "    memsem, to_file='model.png', show_shapes=False, show_layer_names=True,\n",
        "    rankdir='TB', expand_nested=True, dpi=96\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey3HFaIQswKD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint('model-{epoch:03d}-{val_acc:03f}.h5', verbose=1, monitor='val_acc',save_best_only=True, mode='max')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9koAkwuHvlYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out = memsem.fit([train_input_ids,\n",
        "                  train_input_masks,\n",
        "                  train_segment_ids,\n",
        "                  train_imagesX],\n",
        "                  trainY,\n",
        "                    batch_size=50,\n",
        "                    epochs=20,\n",
        "                    \n",
        "                    shuffle=True,\n",
        "                    validation_data=([test_input_ids,\n",
        "                                      test_input_masks, \n",
        "                                      test_segment_ids,\n",
        "                                      test_imagesX],\n",
        "                                     testY))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}